# 2-Layer Cache 전략을 통한 읽기 성능 최적화

## 1. 문제 요약

Shortly는 읽기 중심 서비스로 인기 URL의 캐시가 만료되는 순간 다수의 요청이 동시에 DB로 몰리는 `Cache Stampede` 현상이 발생합니다.

## 2. 해결 전략

### 2.1 Redis 분산 락
Redis의 `SETNX`를 활용하여 락을 획득한 하나의 스레드만 DB를 조회하는 방식이다. 확실한 동시성 제어가 가능하지만, 락 획득/해제 과정에서 네트워크 부하가 발생하고 Redis 장애 시 전체 서비스 영향을 준다.

### 2.2 Jitter
TTL에 무작위 값을 더해 만료 시점을 분산시키는 방식이다. 구현이 간단하지만 확률적인 방법이므로 트래픽이 몰리는 근본적인 문제를 해결하지 못 한다.

### 2.3 Caffeine CacheLoader + refreshAfterWrite (채택)
Caffeine `CacheLoader는` Key별로 락을 거는 방식이다. 동시에 다수의 요청이 발생해도 단 하나의 스레드만 Loader를 실행하고, 나머지 스레드는 대기 후 결과를 공유받는다.

`refreshAfterWrite는` 캐시 TTL이 만료돼도 기존 데이터를 즉시 반환한다. 단축 URL은 불변 데이터이므로, 이를 통해 만료 시점에도 기존 데이터를 즉시 반환하여 사용자 대기 시간을 없애고, 백그라운드에서 비동기적으로 데이터를 갱신할 수 있다.

## 3. 결과
- 초당 3,700건의 요청 발생 → 캐시 히트율 99.996% 달성 및 P95 90ms 이하 유지.
- 캐시 만료 시점에 다수의 요청 생성하여 하나의 요청만 Loader를 실행하는 것을 확인.
