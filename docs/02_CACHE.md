# 2-Layer Cache 전략을 통한 읽기 성능 최적화

## 1. 문제 요약

Shortly는 읽기 중심 서비스로 인기 URL의 캐시가 만료되는 순간 다수의 요청이 동시에 DB로 몰리는 `Cache Stampede` 현상이 발생합니다.

## 2. 해결 전략

### 2.1 Redis 분산 락
Redis의 `SETNX`를 활용하여 락을 획득한 하나의 스레드만 DB를 조회하는 방식이다. 확실한 동시성 제어가 가능하지만, 락 획득/해제 과정에서 네트워크 부하가 발생하고 Redis 장애 시 전체 서비스 영향을 준다.

### 2.2 Jitter
TTL에 무작위 값을 더해 만료 시점을 분산시키는 방식이다. 구현이 간단하지만 확률적인 방법이므로 트래픽이 몰리는 근본적인 문제를 해결하지 못 한다.

### 2.3 Caffeine CacheLoader + refreshAfterWrite (채택)
Caffeine `CacheLoader는` Key별로 락을 거는 방식이다. 동시에 다수의 요청이 발생해도 단 하나의 스레드만 Loader를 실행하고, 나머지 스레드는 대기 후 결과를 공유받는다.

`refreshAfterWrite는` 캐시 TTL이 만료돼도 기존 데이터를 즉시 반환한다. 단축 URL은 불변 데이터이므로, 이를 통해 만료 시점에도 기존 데이터를 즉시 반환하여 사용자 대기 시간을 없애고, 백그라운드에서 비동기적으로 데이터를 갱신할 수 있다.

## 3. 결과

| 지표 | 개선 전 | 개선 후 | 개선율 |
| :--- | :--- | :--- | :--- |
| **P95 Latency (Peak)** | 180ms | 90ms | **50% 감소** |
| **URL Service CPU (Peak)** | 90% | 40% | **55% 감소** |
| **DB Connection Pool** | 98/100 (고갈) | 50/100 (안정) | **50% 여유** |
| **Timeout** | 23건 | 0건 | **100% 제거** |
