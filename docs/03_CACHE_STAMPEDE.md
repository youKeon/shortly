## 1. 문제 배경

- URL 단축 서비스는 Read-Heavy 시스템 (읽기:쓰기 = 100:1)
- 인기 URL의 캐시가 만료되는 순간, 다수의 요청이 동시에 DB로 몰리는 `Cache Stampede` 발생 가능

## 2. 해결 전략 비교

### 2.1 Redis 분산 락
- Redis `SETNX`로 락을 획득한 하나의 스레드만 DB 조회
- 락 획득/해제 과정에서 네트워크 부하
- Redis 장애 시 전체 서비스 장애

### 2.2 TTL Jitter
- TTL에 무작위 값을 더해 만료 시점 분산
- 확률적 방법으로 트래픽 몰림 완전 해결 불가

### 2.3 Caffeine LoadingCache + refreshAfterWrite (채택)

#### 선택 이유
- `동시성 제어`: Key별 락으로 DB 조회 1회 보장
- `불변 데이터 특성 활용`: url은 불변 -> refreshAfterWrite로 Stale 데이터 반환해도 안전

## 3. 동작 원리

### 3.1 LoadingCache 동시성 보장

- 캐시 만료 시점에 동시에 여러 요청이 발생하면:
  - 첫 번째 요청만 DB 조회 실행
  - 나머지 요청은 락 대기 후 결과 공유
- DB 조회는 1회만 발생

### 3.2 refreshAfterWrite 동작

- 캐시 만료 시점에 동시에 여러 요청이 발생하면:
  - 모든 요청에 기존 데이터 즉시 반환
  - 백그라운드에서 1개 스레드만 갱신 수행
- 사용자 대기 시간 0

## 4. 결과

| 지표 | 값         |
|------|-----------|
| 테스트 시간 | 30분       |
| 총 리다이렉트 요청 | 1,500만건   |
| 캐시 히트율 | **91.8%** |
