## 1. 문제 배경

- URL 단축 서비스는 Read-Heavy 시스템
- 인기 URL의 캐시가 만료되는 순간 다수의 요청이 동시에 DB로 몰리는 `Cache Stampede` 발생 가능

## 2. 해결 전략

### 2.1 Redis 분산 락
- Redis의 `SETNX`를 활용하여 락을 획득한 하나의 스레드만 DB를 조회하는 방식
- 확실한 동시성 제어가 가능하지만, 락 획득/해제 과정에서 네트워크 부하가 발생하고 Redis 장애 시 전체 서비스 장애

### 2.2 Jitter
- TTL에 무작위 값을 더해 만료 시점을 분산시키는 방식
- 구현이 간단하지만, 확률적인 방법이므로 트래픽이 몰리는 문제는 해결 불가능

### 2.3 Caffeine CacheLoader + refreshAfterWrite (채택)
- Caffeine 라이브러리에서 제공하는 `CacheLoader` `refreshAfterWrite` 설정 활용
- `CacheLoader`: Key별로 락을 거는 방식
  - 동시에 다수의 요청이 발생해도 단 하나의 스레드만 Loader를 실행하고, 나머지 스레드는 대기 후 결과를 공유받음
- `refreshAfterWrite`: 캐시가 만료돼도 기존 데이터를 즉시 반환
  - 단축 URL은 불변 데이터이므로, 기존 데이터를 즉시 반환하여 사용자 대기 시간을 없애고, 비동기로 데이터 갱신

## 3. 결과
- 초당 3,700건의 요청 발생 → 캐시 히트율 99.996% 달성 및 P95 90ms 이하 유지.
- 캐시 만료 시점에 다수의 요청 생성하여 하나의 요청만 Loader를 실행하는 것을 확인.
